= Runtime Component Operator

This generic Operator is capable of deploying any application image and can be imported into any runtime-specific Operator as library of application capabilities.  This architecture ensures compatibility and consistency between all runtime Operators, allowing everyone to benefit from the functionality added in this project.

This documentation refers to the latest codebase.  For documentation and samples of older releases, please check out the link:++https://github.com/application-stacks/runtime-component-operator/releases++[main releases] page and navigate the corresponding tag.

== Operator installation

Use the instructions for one of the link:++../deploy/releases++[releases] to install the operator into a Kubernetes cluster.

The Runtime Component Operator can be installed to:

* watch own namespace
* watch another namespace
* watch multiple namespaces
* watch all namespaces in the cluster

Appropriate cluster roles and bindings are required to watch another namespace, watch multiple namespaces or watch all namespaces.

NOTE: The Runtime Component Operator can only interact with resources it is given permission to interact through link:++https://kubernetes.io/docs/reference/access-authn-authz/rbac/++[Role-based access control (RBAC)]. Some of the operator features described in this document require interacting with resources in other namespaces. In that case, the operator must be installed with correct `ClusterRole` definitions.

== Overview

The architecture of the Runtime Component Operator follows the basic controller pattern:  the Operator container with the controller is deployed into a Pod and listens for incoming resources with `Kind: RuntimeComponent`. Creating a `RuntimeComponent` custom resource (CR) triggers the Runtime Component Operator to create, update or delete Kubernetes resources needed by the application to run on your cluster.

Each instance of `RuntimeComponent` CR represents the application to be deployed on the cluster:

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  service:
    type: ClusterIP
    port: 9080
  expose: true
  statefulSet:
    storage:
      size: 2Gi
      mountPath: "/logs"
----

== Configuration

=== Custom Resource Definition (CRD)

The following table lists configurable parameters of the `RuntimeComponent` CRD. For complete OpenAPI v3 representation of these values please see link:++../deploy/crds/app.stacks_runtimecomponents_crd.yaml++[`RuntimeComponent` CRD].

Each `RuntimeComponent` CR must at least specify the `applicationImage` parameter. Specifying other parameters is optional.

.Runtime Component Resource Definition
|===
| Parameter | Description

| `version` | The current version of the application. Label `app.kubernetes.io/version` will be added to all resources when the version is defined.
| `serviceAccountName` | The name of the OpenShift service account to be used during deployment.
| `applicationImage` | The Docker image name to be deployed. On OpenShift, it can also be set to `<project name>/<image stream name>[:<tag>]` to reference an image from an image stream. If `<project name>` and `<tag>` values are not defined, they default to the namespace of the CR and the value of `latest`, respectively.
| `applicationName` | The name of the application this resource is part of. If not specified, it defaults to the name of the CR.
| `createAppDefinition`   | A boolean to toggle the automatic configuration of Kubernetes resources for the `RuntimeComponent` CR to allow creation of an application definition by link:++https://kappnav.io++[kAppNav]. The default value is `true`. See link:++#kubernetes-application-navigator-kappnav-support++[Application Navigator] for more information.
| `pullPolicy` | The policy used when pulling the image.  One of: `Always`, `Never`, and `IfNotPresent`.
| `pullSecret` | If using a registry that requires authentication, the name of the secret containing credentials.
| `initContainers` | The list of link:++https://v1-17.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#container-v1-core++[Init Container] definitions.
| `sidecarContainers` | The list of `sidecar` containers. These are additional containers to be added to the pods. Note: Sidecar containers should not be named `app`.
| `architecture` | An array of architectures to be considered for deployment. Their position in the array indicates preference.
| `bindings.embedded` | A YAML object that represents a `ServiceBindingRequest` custom resource.
| `bindings.autoDetect` | A boolean to toggle whether the operator should automatically detect and use a `ServiceBindingRequest` resource with `<CR_NAME>-binding` naming format. The default value for this parameter is `true`.
| `bindings.resourceRef` | The name of a `ServiceBindingRequest` custom resource created manually in the same namespace as the application.
| `bindings.expose.enabled` | A boolean to toggle whether the operator expose the application as a bindable service. The default value for this parameter is `false`.
| `service.port` | The port exposed by the container.
| `service.targetPort` | The port that the operator assigns to containers inside pods. Defaults to the value of `service.port`.
| `service.portName` | The name for the port exposed by the container.
| `service.ports` | An array consisting of service ports.
| `service.type` | The Kubernetes link:++https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types++[Service Type].
| `service.nodePort` | Node proxies this port into your service. Please note once this port is set to a non-zero value it cannot be reset to zero.
| `service.annotations` | Annotations to be added to the service.
| `service.certificate` | A YAML object that represents a link:++https://cert-manager.io/docs/reference/api-docs/#cert-manager.io/v1alpha2.CertificateSpec++[Certificate].
| `service.certificateSecretRef` | A name of a secret that already contains TLS key, certificate and CA to be mounted in the pod.
| `service.provides.category` | Service binding type to be provided by this CR. At this time, the only allowed value is `openapi`.
| `service.provides.protocol` | Protocol of the provided service. Defauts to `http`.
| `service.provides.context` | Specifies context root of the service.
| `service.provides.auth.username` | Optional value to specify username as link:++https://v1-17.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#secretkeyselector-v1-core++[SecretKeySelector].
| `service.provides.auth.password` | Optional value to specify password as link:++https://v1-17.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#secretkeyselector-v1-core++[SecretKeySelector].
| `service.consumes` | An array consisting of services to be consumed by the `RuntimeComponent`.
| `service.consumes[].category` | The type of service binding to be consumed. At this time, the only allowed value is `openapi`.
| `service.consumes[].name` | The name of the service to be consumed. If binding to a `RuntimeComponent`, then this would be the provider's CR name.
| `service.consumes[].namespace` | The namespace of the service to be consumed. If binding to a `RuntimeComponent`, then this would be the provider's CR namespace.
| `service.consumes[].mountPath` | Optional field to specify which location in the pod, service binding secret should be mounted. If not specified, the secret keys would be injected as environment variables.
| `createKnativeService`   | A boolean to toggle the creation of Knative resources and usage of Knative serving.
| `expose`   | A boolean that toggles the external exposure of this deployment via a Route or a Knative Route resource.
| `deployment.updateStrategy`   | A field to specify the update strategy of the deployment. For more information, see link:++https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy++[updateStrategy]
| `deployment.updateStrategy.type`   | The type of update strategy of the deployment. The type can be set to `RollingUpdate` or `Recreate`, where `RollingUpdate` is the default update strategy.
| `deployment.annotations`   | Annotations to be added only to the deployment and resources owned by the deployment.
| `statefulSet.updateStrategy`   | A field to specify the update strategy of the StatefulSet. For more information, see link:++https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies++[updateStrategy]
| `statefulSet.updateStrategy.type`   | The type of update strategy of the StatefulSet. The type can be set to `RollingUpdate` or `OnDelete`, where `RollingUpdate` is the default update strategy.
| `statefulSet.annotations`   | Annotations to be added only to the StatefulSet and resources owned by the StatefulSet.
| `replicas` | The static number of desired replica pods that run simultaneously.
| `autoscaling.maxReplicas` | Required field for autoscaling. Upper limit for the number of pods that can be set by the autoscaler. It cannot be lower than the minimum number of replicas.
| `autoscaling.minReplicas`   | Lower limit for the number of pods that can be set by the autoscaler.
| `autoscaling.targetCPUUtilizationPercentage`   | Target average CPU utilization (represented as a percentage of requested CPU) over all the pods.
| `resourceConstraints.requests.cpu` | The minimum required CPU core. Specify integers, fractions (e.g. 0.5), or millicore values(e.g. 100m, where 100m is equivalent to .1 core). Required field for autoscaling.
| `resourceConstraints.requests.memory` | The minimum memory in bytes. Specify integers with one of these suffixes: E, P, T, G, M, K, or power-of-two equivalents: Ei, Pi, Ti, Gi, Mi, Ki.
| `resourceConstraints.limits.cpu` | The upper limit of CPU core. Specify integers, fractions (e.g. 0.5), or millicores values(e.g. 100m, where 100m is equivalent to .1 core).
| `resourceConstraints.limits.memory` | The memory upper limit in bytes. Specify integers with suffixes: E, P, T, G, M, K, or power-of-two equivalents: Ei, Pi, Ti, Gi, Mi, Ki.
| `env`   | An array of environment variables following the format of `{name, value}`, where value is a simple string. It may also follow the format of `{name, valueFrom}`, where valueFrom refers to a value in a `ConfigMap` or `Secret` resource. See link:++#environment-variables++[Environment variables] for more info.
| `envFrom`   | An array of references to `ConfigMap` or `Secret` resources containing environment variables. Keys from `ConfigMap` or `Secret` resources become environment variable names in your container. See link:++#environment-variables++[Environment variables] for more info.
| `readinessProbe`   | A YAML object configuring the link:++https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-readiness-probes++[Kubernetes readiness probe] that controls when the pod is ready to receive traffic.
| `livenessProbe` | A YAML object configuring the link:++https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-liveness-http-request++[Kubernetes liveness probe] that controls when Kubernetes needs to restart the pod.
| `startupProbe` | A YAML object configuring the link:++https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-startup-probes++[Kubernetes startup probe] that controls when Kubernetes needs to startup the pod on its first initialization.
| `volumes` | A YAML object that represents a link:++https://kubernetes.io/docs/concepts/storage/volumes++[pod volume].
| `volumeMounts` | A YAML object that represents a link:++https://kubernetes.io/docs/concepts/storage/volumes/++[pod volumeMount].
| `statefulSet.storage.size` | A convenient field to set the size of the persisted storage. Can be overridden by the `storage.volumeClaimTemplate` property.
| `statefulSet.storage.mountPath` | The directory inside the container where this persisted storage will be bound to.
| `statefulSet.storage.volumeClaimTemplate` | A YAML object that represents a link:++https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#components++[volumeClaimTemplate] component of a `StatefulSet`.
| `monitoring.labels` | Labels to set on link:++https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#servicemonitor++[ServiceMonitor].
| `monitoring.endpoints` | A YAML snippet representing an array of link:++https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint++[Endpoint] component from ServiceMonitor.
| `route.annotations` | Annotations to be added to the Route.
| `route.host`   | Hostname to be used for the Route.
| `route.path`   | Path to be used for Route.
| `route.termination`   | TLS termination policy. Can be one of `edge`, `reencrypt` and `passthrough`.
| `route.insecureEdgeTerminationPolicy`   | HTTP traffic policy with TLS enabled. Can be one of `Allow`, `Redirect` and `None`.
| `route.certificate`  | A YAML object that represents a link:++https://cert-manager.io/docs/reference/api-docs/#cert-manager.io/v1alpha2.CertificateSpec++[Certificate].
| `route.certificateSecretRef` | A name of a secret that already contains TLS key, certificate and CA to be used in the route. Also can contain destination CA certificate.
| `affinity.nodeAffinity` | A YAML object that represents a link:++https://v1-17.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#nodeaffinity-v1-core++[NodeAffinity].
| `affinity.nodeAffinityLabels` | A YAML object that contains set of required labels and their values.
| `affinity.podAffinity` | A YAML object that represents a link:++https://v1-17.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#podaffinity-v1-core++[PodAffinity].
| `affinity.podAntiAffinity` | A YAML object that represents a link:++https://v1-17.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#podantiaffinity-v1-core++[PodAntiAffinity].

|===

=== Basic usage

To deploy a Docker image that contains a runtime component to a Kubernetes environment, you can use the following CR:

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
----

The `applicationImage` value must be defined in the `RuntimeComponent` CR. On OpenShift, the operator tries to find an image stream name with the `applicationImage` value. The operator falls back to the registry lookup if it is not able to find any image stream that matches the value. If you want to distinguish an image stream called `my-company/my-app` (project: `my-company`, image stream name: `my-app`) from the Docker Hub `my-company/my-app` image, you can use the full image reference as `docker.io/my-company/my-app`.

To get information on the deployed CR, use either of the following:

[source,sh]
----
oc get runtimecomponent my-app
oc get comp my-app
----

The short name for `runtimecomponent` is `comp`.


=== Image Streams

To deploy an image from an image stream, use the following CR:

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
spec:
  applicationImage: my-namespace/my-image-stream:1.0
----

The previous example looks up the `1.0` tag from the `my-image-stream` image stream in the `my-namespace` project and populates the CR `.status.imageReference` field with the exact referenced image similar to the following one: `image-registry.openshift-image-registry.svc:5000/my-namespace/my-image-stream@sha256:8a829d579b114a9115c0a7172d089413c5d5dd6120665406aae0600f338654d8`. The operator watches the specified image stream and deploys new images as new ones are available for the specified tag.

To reference an image stream, the `applicationImage` parameter must follow the `<project name>/<image stream name>[:<tag>]` format. If `<project name>` or `<tag>` is not specified, the operator defaults the values to the namespace of the CR and the value of `latest`, respectively. For example, the `applicationImage: my-image-stream` configuration is the same as the `applicationImage: my-namespace/my-image-stream:latest` configuration.

The Operator tries to find an image stream name first with the `<project name>/<image stream name>[:<tag>]` format and falls back to the registry lookup if it is not able to find any image stream that matches the value.

_This feature is only available if you are running on OKD or OpenShift._

NOTE: The operator requires `ClusterRole` permissions if the image stream resource is in another namespace.

=== Service account

The operator can create a `ServiceAccount` resource when deploying a `RuntimeComponent` custom resource (CR). If `serviceAccountName` is not specified in a CR, the operator creates a service account with the same name as the CR (e.g. `my-app`).

Users can also specify `serviceAccountName` when they want to create a service account manually.

If applications require specific permissions but still want the operator to create a `ServiceAccount`, users can still manually create a role binding to bind a role to the service account created by the operator. To learn more about Role-based access control (RBAC), see Kubernetes link:++https://kubernetes.io/docs/reference/access-authn-authz/rbac/++[documentation].

=== Labels

By default, the operator adds the following labels into all resources created
for a `RuntimeComponent` CR:

.Default Labels
|===
| Label                          | Default                        | Description

| `app.kubernetes.io/instance`   | `metadata.name`                | A unique name or identifier for this component. This cannot be modified.
| `app.kubernetes.io/name`       | `metadata.name`                | A name that represents this component.
| `app.kubernetes.io/managed-by` | `runtime-component-operator`   | The tool being used to manage this component.
| `app.kubernetes.io/component`  | `backend`                      | The type of component being created. See OpenShift link:++https://github.com/gorkem/app-labels/blob/master/labels-annotation-for-openshift.adoc#labels++[documentation] for full list.
| `app.kubernetes.io/part-of`    | `applicationName`              | The name of the higher-level application this component is a part of. Configure this if the component is not a standalone application.
| `app.kubernetes.io/version`    | `version`                      | The version of the component.
|===


You can set new labels in addition to the pre-existing ones or overwrite them,
excluding the `app.kubernetes.io/instance` label. To set labels, specify them in
your CR as key/value pairs.

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
  labels:
    my-label-key: my-label-value
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
----

_After the initial deployment of `RuntimeComponent`, any changes to its labels would be applied only when one of the parameters from `spec` is updated._

==== OpenShift Recommended Labels

When running in OpenShift, there are additional labels and annotations that are
standard on the platform. It is recommended that you overwrite our defaults
where applicable and add any labels from the list that are not set by default using the above instructions. See link:++https://github.com/gorkem/app-labels/blob/master/labels-annotation-for-openshift.adoc#labels++[documentation] for a full list.

=== Annotations

To add new annotations into all resources created for a `RuntimeComponent`, specify them in your CR as key/value pairs. Annotations specified in CR would override any annotations specified on a resource, except for the annotations set on `Service` using `service.annotations`.

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
  annotations:
    my-annotation-key: my-annotation-value
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
----

_After the initial deployment of `RuntimeComponent`, any changes to its annotations would be applied only when one of the parameters from `spec` is updated._

==== OpenShift Recommended Annotations

When running in OpenShift, there are additional annotations that are
standard on the platform. It is recommended that you overwrite our defaults
where applicable and add any annotations from the list that are not set by
default using the above instructions. See link:++https://github.com/gorkem/app-labels/blob/master/labels-annotation-for-openshift.adoc#labels++[documentation] for a full list.

=== Environment variables

You can set environment variables for your application container. To set
environment variables, specify `env` and/or `envFrom` fields in your CR. The
environment variables can come directly from key/value pairs, `ConfigMap`s or
`Secret`s. The environment variables set using the `env` or `envFrom` fields will
override any environment variables specified in the container image.

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  env:
    - name: DB_NAME
      value: "database"
    - name: DB_PORT
      valueFrom:
        configMapKeyRef:
          name: db-config
          key: db-port
    - name: DB_USERNAME
      valueFrom:
        secretKeyRef:
          name: db-credential
          key: adminUsername
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: db-credential
          key: adminPassword
  envFrom:
    - configMapRef:
        name: env-configmap
    - secretRef:
        name: env-secrets
----

Use `envFrom` to define all data in a `ConfigMap` or a `Secret` as environment variables in a container. Keys from `ConfigMap` or `Secret` resources become environment variable name in your container.

=== High availability

Run multiple instances of your application for high availability using one of the following mechanisms:

  - specify a static number of instances to run at all times using `replicas` parameter.

__OR__

  - configure auto-scaling to create (and delete) instances based on resource consumption using the `autoscaling` parameter.
  - Parameters `autoscaling.maxReplicas` and `resourceConstraints.requests.cpu` MUST be specified for auto-scaling.

=== Service ports

Runtime Component Operator allows you to provide multiple service ports in addition to the primary service port. The primary port is exposed from the container running the application and it's values are used to configure the Route (or Ingress), Service binding and Knative service.
The primary service port can be configured using `service.port`, `service.targetPort`, `service.portName`, and `service.nodePort` parameters.

You can also specify an alternative port for Service Monitor using the `monitoring.endpoints` parameter and specifying either the `port` or `targetPort` field, otherwise it defaults to the primary port.

The primary port is under the `service` field and the additional ports can be specified using the `ports` field as shown below.

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  service:
    type: NodePort
    port: 9080
    portName: http
    targetPort: 9080
    nodePort: 30008
    ports:
      - port: 9443
        name: https
  monitoring:
    endpoints:
      - basicAuth:
          password:
            key: password
            name: metrics-secret
          username:
            key: username
            name: metrics-secret
        interval: 5s
        port: https
        scheme: HTTPS
        tlsConfig:
          insecureSkipVerify: true
    labels:
      app-monitoring: 'true'
----

=== Persistence

Runtime Component Operator is capable of creating a `StatefulSet` and `PersistentVolumeClaim` for each pod if storage is specified in the `RuntimeComponent` CR.

Users also can provide mount points for their application. There are 2 ways to enable storage.

==== Basic storage

With the `RuntimeComponent` CR definition below the operator will create `PersistentVolumeClaim` called `pvc` with the size of `1Gi` and `ReadWriteOnce` access mode.

The operator will also create a volume mount for the `StatefulSet` mounting to `/data` folder. You can use `volumeMounts` field instead of `statefulSet.storage.mountPath` if you require to persist more then one folder.

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  statefulSet:
    storage:
      size: 1Gi
      mountPath: "/data"
----

==== Advanced storage

Runtime Component Operator allows users to provide entire `volumeClaimTemplate` for full control over automatically created `PersistentVolumeClaim`.

It is also possible to create multiple volume mount points for persistent volume using `volumeMounts` field as shown below. You can still use `statefulSet.storage.mountPath` if you require only a single mount point.

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  volumeMounts:
  - name: pvc
    mountPath: /data_1
    subPath: data_1
  - name: pvc
    mountPath: /data_2
    subPath: data_2
  statefulSet:
    storage:
      volumeClaimTemplate:
        metadata:
          name: pvc
        spec:
          accessModes:
          - "ReadWriteMany"
          storageClassName: 'glusterfs'
          resources:
            requests:
              storage: 1Gi
----

=== Service binding

==== Service Binding Operator

The link:++https://github.com/redhat-developer/service-binding-operator++[Service Binding Operator] enables application developers to bind applications together with operator-managed backing services. This can be achieved by creating a `ServiceBindingRequest` custom resource.


For the Runtime Component Operator to pass the binding information to the application, define your `ServiceBindingRequest` custom resource in one of the following two ways:

. Define the `ServiceBindingRequest` custom resource YAML within the `bindings.embedded` parameter in your `RuntimeComponent` custom resource.
. Create the `ServiceBindingRequest` custom resource manually and either refer to it explicitly in your `RuntimeComponent` custom resource or let the operator detect it automatically. The auto-detection mechanism works only if the `ServiceBindingRequest` custom resource follows the `<CR_NAME>-binding` naming convention.

===== Embedding the Service Binding resource

Define your `ServiceBindingRequest` custom resource within your `RuntimeComponent` custom resource:

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  bindings:
    embedded:
      apiVersion: apps.openshift.io/v1alpha1
      kind: ServiceBindingRequest
      spec:
        backingServiceSelectors:
          - group: kafka.strimzi.io
            kind: Kafka
            resourceRef: my-cluster
            version: v1beta1
----

After the Runtime Component Operator processes the `RuntimeComponent` custom resource, it creates a `ServiceBindingRequest` custom resource named `my-app-binding`.

After the Service Binding Operator processes the `my-app` custom resource of the `ServiceBindingRequest` type, it creates a `Secret` object. The `Secret` resource contains binding information that the backing service provides. The Runtime Component Operator injects the `Secret` resource as an environment variable into application pods.

The YAML definition specified in the `bindings.embedded` parameter must not include a `metadata` section because the Runtime Component operator adds a `metadata` section. If the YAML definition does not include an `apiVersion` field or a `kind` field, the Runtime Component operator uses the default `GroupVersionKind` value specified in the Operator Config Map.

===== Creating the Service Binding resource externally

Create your `ServiceBindingRequest` custom resource in a separate YAML definition and then refer to the resource within your `RuntimeComponent` custom resource:

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  bindings:
    resourceRef: my-binding
----

After the Service Binding Operator, as defined previously, processes the `my-binding` custom resource of the `ServiceBindingRequest` type, it creates a `Secret` object. The `Secret` resource contains binding information that the backing service provides. The Runtime Component Operator injects the `Secret` resource as an environment variable into application pods.

The Runtime Component Operator can also _automatically detect_ if a `ServiceBindingRequest` custom resource exists in the application namespace and is named `<CR_NAME>-binding` (e.g. `my-app-binding`). If the operator detects the custom resource, it injects the binding secret into the application container.

Users can turn off the auto-detection mechanism by setting the `bindings.autoDetect` parameter to a value of `false`. The `bindings.resourceRef` parameter takes precedence over the `bindings.autoDetect` parameter. In other words, the Runtime Component Operator, injects secrets from the `my-binding` resource, even if a `ServiceBindingRequest` resource named `my-app-binding` exists:

[source,yaml]
----
  bindings:
    autoDetect: true
    resourceRef: my-binding
----

_This feature is only available if you have Service Binding Operator installed on your cluster._

==== Exposing `RuntimeComponent` applications as Provisioned Services

A `RuntimeComponent` application can be configured to behave as a link:++https://github.com/k8s-service-bindings/spec#provisioned-service++[Provisioned Service] defined by the link:++https://github.com/k8s-service-bindings/spec++[Service Binding Specification].

According to the specification, a Provisioned Service resource must define a `.status.binding.name` which is a reference to a Secret.
To expose your application as a Provisioned Service, set the `.spec.bindings.expose.enabled` parameter to a value of `true`. The Runtime Component Operator creates a *binding secret* named `<CR_NAME>-expose-binding` and adds the following entries to the secret: `host`, `port`, `protocol`, `basePath` and `uri`.

To override the default values for the entries in the binding secret or to add new entries to the secret, create an *override secret* named `<CR_NAME>-expose-binding-override` and add any entries to the secret. The operator reads the content of the override secret and overrides the default values in the binding secret.

Once a `RuntimeComponent` application is exposed as a Provisioned Service, a service binding request can refer to the application as a backing service.

==== Binding to `RuntimeComponent` applications

Runtime Component Operator can be used to help with service binding in a cluster. The operator creates a secret on behalf of the **provider** `RuntimeComponent` and injects the secret into pods of the **consumer** `RuntimeComponent` as either environment variable or mounted files. See link:++https://docs.google.com/document/d/1riOX0iTnBBJpTKAHcQShYVMlgkaTNKb4m8fY7W1GqMA/edit++[Runtime Component Operator Design for Service Binding] for more information on the architecture. At this time, the only supported service binding type is `openapi`.

The provider lists information about the REST API it provides:

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-provider
  namespace: pro-namespace
spec:
  applicationImage: quay.io/my-repo/my-provider:1.0
  service:
    port: 3000
    provides:
      category: openapi
      context: /my-context
      auth:
        password:
          name: my-secret
          key: password
        username:
          name: my-secret
          key: username
---
kind: Secret
apiVersion: v1
metadata:
  name: my-secret
  namespace: pro-namespace
data:
  password: bW9vb29vb28=
  username: dGhlbGF1Z2hpbmdjb3c=
type: Opaque
----

And the consumer lists the services it is intending to consume:

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-consumer
  namespace: con-namespace
spec:
  applicationImage: quay.io/my-repo/my-consumer:1.0
  expose: true
  service:
    port: 9080
    consumes:
    - category: openapi
      name: my-provider
      namespace: pro-namespace
      mountPath: /sample
----

In the above example, the operator creates a secret named `pro-namespace-my-provider` and adds the following key-value pairs: `username`, `password`, `url`, `context`, `protocol` and `hostname`. The `url` value format is `<protocol>://<name>.<namespace>.svc.cluster.local:<port>/<context>`. Since the provider and the consumer are in two different namespaces, the operator copies the provider secret into consumer's namespace. The operator then mounts the provider secret into a directory with the pattern `<mountPath>/<namespace>/<service_name>` on application container within pods. In the above example, the secret will be serialized into `/sample/pro-namespace/my-provider`, which means we will have a file for each key, where the filename is the key and the content is the key's value.

If the `namespace` is not provided in the above example under `consumes`, then the operator mounts the provider secret into a directory with pattern `<mountPath>/<service_name>`.

If consumer's CR does not include `mountPath`, the secret will be bound to environment variables with the pattern `<NAMESPACE>_<SERVICE-NAME>_<KEY>`, and the value of that env var is the key’s value. Due to syntax restrictions for Kubernetes environment variables, the string representing the namespace and the string representing the service name will have to be normalized by turning any non-`[azAZ09]` characters to become an underscore `(_)` character.

NOTE: The operator requires `ClusterRole` permissions if the provider application is in another namespace.

=== Monitoring

Runtime Component Operator can create a `ServiceMonitor` resource to integrate with `Prometheus Operator`.

_This feature does not support integration with Knative Service. Prometheus Operator is required to use ServiceMonitor._

==== Basic monitoring specification

At minimum, a label needs to be provided that Prometheus expects to be set on `ServiceMonitor` objects. In this case, it is `apps-prometheus`.

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  monitoring:
    labels:
       apps-prometheus: ''
----

==== Advanced monitoring specification

For advanced scenarios, it is possible to set many `ServicerMonitor` settings such as authentication secret using link:++https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint++[Prometheus Endpoint]

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  monitoring:
    labels:
       app-prometheus: ''
    endpoints:
    - interval: '30s'
      basicAuth:
        username:
          key: username
          name: metrics-secret
        password:
          key: password
          name: metrics-secret
      tlsConfig:
        insecureSkipVerify: true
----

=== Knative support

Runtime Component Operator can deploy serverless applications with link:++https://knative.dev/docs/++[Knative] on a Kubernetes cluster. To achieve this, the operator creates a link:++https://github.com/knative/serving/blob/master/docs/spec/spec.md#service++[Knative `Service`] resource which manages the whole life cycle of a workload.

To create Knative service, set `createKnativeService` to `true`:

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  createKnativeService: true
----

By setting this parameter, the operator creates a Knative service in the cluster and populates the resource with applicable `RuntimeComponent` fields. Also, it ensures non-Knative resources including Kubernetes `Service`, `Route`, `Deployment` and etc. are deleted.

The CRD fields which are used to populate the Knative service resource include `applicationImage`, `serviceAccountName`, `livenessProbe`, `readinessProbe`, `service.Port`, `volumes`, `volumeMounts`, `env`, `envFrom`, `pullSecret` and `pullPolicy`. `startupProbe` is not fully supported by Knative and it will not apply when Knative service is enabled.

For more details on how to configure Knative for tasks such as enabling HTTPS connections and setting up a custom domain, checkout link:++https://knative.dev/docs/serving/++[Knative Documentation].

_Autoscaling related fields in `RuntimeComponent` are not used to configure Knative Pod Autoscaler (KPA). To learn more about how to configure KPA, see link:++https://knative.dev/docs/serving/configuring-the-autoscaler/++[Configuring the Autoscaler]._

_This feature is only available if you have Knative installed on your cluster._

=== Exposing service externally

==== Non-Knative deployment (Route)

To expose your application externally, set `expose` to `true`:

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  expose: true
----

By setting this parameter, the operator creates an unsecured route based on your application service. Setting this parameter is the same as running `oc expose service <service-name>`.

To create a secured HTTPS route, see the link:++#certificate-manager-integration++[Certificate Manager Integration] section for more information.

_This feature is only available if you are running on OKD or OpenShift._


==== Non-Knative deployment (Ingress)

Before you can use the Ingress resource to expose your cluster, you must install an ingress controller, such a Nginx or Traefik.

_The Ingress resource is created only if the `Route` resource is not available._


To use the Ingress resource, set the `defaultHostName` variable in the _runtime-component-operator_ ConfigMap object to a host name such as _mycompany.com_


===== Simple Ingress that uses `defaultHostName` and no `TLS`:

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
  namespace: backend
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  expose: true
----

With default hostname of _mycompany.com_, the application is available at the http://my-app-backend.mycompany.com URL.


===== Enable TLS and generate a certificate by using the cert-manager controller:

_Note: You must install the cert-manager controller to automatically generate a custom certificate for the ingress controller._

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
  namespace: backend
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  expose: true
  route:
    certificate: {}
----

===== Advanced Ingress configuration:

Most of the Ingress configuraiton is achieved through annotations. Annotations such as Nginx, HAProxy, Traefik, and others are specific to the ingress controller implementation.

You can provide an existing TLS secret and set a custom hostname.

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
  namespace: backend
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  expose: true
  route:
    annotations:
      # You can use this annotation to specify the name of the ingress controller to use.
      # You can install multiple ingress controllers to address different types of incoming traffic such as an external or internal DNS.
      kubernetes.io/ingress.class: "nginx" 
      
      # The following nginx annotation enables a secure pod connection:
      nginx.ingress.kubernetes.io/ssl-redirect: true
      nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"

      # The following traefik annotation enables a secure pod connection:
      traefik.ingress.kubernetes.io/service.serversscheme: https

    # Use a custom hostname for the Ingress
    host: app-v1.mycompany.com
    # Reference a pre-existing TLS secret:
    certificateSecretRef: mycompany-tls
----

==== Knative deployment

To expose your application as a Knative service externally, set `expose` to `true`:

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  createKnativeService: true
  expose: true
----

When `expose` is **not** set to `true`, the Knative service is labeled with `serving.knative.dev/visibility=cluster-local` which makes the Knative route to only be available on the cluster-local network (and not on the public Internet). However, if `expose` is set `true`, the Knative route would be accessible externally.

To configure secure HTTPS connections for your Knative deployment, see link:++https://knative.dev/docs/serving/using-a-tls-cert/++[Configuring HTTPS with TLS certificates] for more information.

=== Kubernetes Application Navigator (kAppNav) support

By default, Runtime Component Operator configures the Kubernetes resources it generates to allow automatic creation of an link:++https://github.com/kubernetes-sigs/application++[Application definition] with the `applicationName` parameter as the `Application` CR name. The automatic creation is done by the link:++https://kappnav.io/++[Kubernetes Application Navigator (kAppNav)]. You can easily view and manage the deployed resources that comprise your application by using kAppNav. You can disable auto-creation by setting the `createAppDefinition` parameter to a value of `false`.

To join an existing application definition in the `RuntimeComponent` CR namespace, ensure that the `applicationName` parameter is set to the name of the `Application` CR that you want to join. To join an existing application definition in another namespace, ensure that the `createAppDefinition` parameter is set to `false` and that the `applicationName` parameter is set to the name of the existing `Application` CR that you want to join.

First, the operator searches in the `RuntimeComponent` CR namespace to find an `Application` CR named as the `applicationName` parameter.
If it fails to find any, it searches the whole cluster to find `Application` CRs that meet the following criteria:

- The `Application` CRs have the same name as the value of the `applicationName` parameter.
- The `RuntimeComponent` CR namespace is listed in the value of the `kappnav.component.namespaces` annotation.

After the operator finds any `Application` CRs in the previous steps, it adds labels to the `RuntimeComponent` CR. These labels are listed in the `spec.selector.matchLabels` parameter. However, if the operator fails to find any `Application` CRs, and if the `createAppDefinition` parameter is not set to `false`, the operator configures the Kubernetes resources it generates. These Kubernetes resources are configured to allow automatic creation of an `Application` definition.

_This feature is only available if you have kAppNav installed on your cluster. Auto creation of an application definition is not supported when Knative service is created_

NOTE: The operator requires `ClusterRole` permissions when joining an existing `Application` custom resource in another namespace.

=== Certificate Manager Integration

Runtime Component Operator is enabled to take advantage of link:++https://cert-manager.io/++[cert-manager] tool, if it is installed on the cluster.
This allows to automatically provision TLS certificates for pods as well as routes.

Cert-manager installation instruction can be found link:++https://cert-manager.io/docs/installation/++[here].

When creating certificates via the RuntimeComponent CR the user can specify a particular issuer name and toggle the scopes between `ClusterIssuer` (cluster scoped) and `Issuer` (namespace scoped). If not specified, these values are retrieved from a ConfigMap called `runtime-component-operator`, with keys `defaultIssuer` (default value of `self-signed`) and `useClusterIssuer` (default value of `"true"`).

_This feature does not support integration with Knative Service._


==== Create an ClusterIssuer or Issuer

Self signed:

[source,yaml]
----
apiVersion: cert-manager.io/v1alpha2
kind: ClusterIssuer
metadata:
  name: self-signed
spec:
  selfSigned: {}
----

Using custom CA key:

[source,yaml]
----
apiVersion: cert-manager.io/v1alpha2
kind: ClusterIssuer
metadata:
  name: mycompany-ca
spec:
  ca:
    secretName: mycompany-ca-tls
----


==== Simple scenario (Pods certificate)

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
  namespace: test
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  ....
  service:
    port: 9080
    certificate: {}
----

In this scenario the operator generates a `Certificate` resource with a common name of `my-app.test.svc` that can be used for service to service communication.

After this certificate request is resolved by the certificate manager, the resulting `my-app-svc-tls` secret is mounted onto each pod inside the `/etc/x509/certs` folder. Mounted files are always up to date with a secret.

It will contain private key, certificate and CA certificate. It is up to the application container to consume these artifacts, applying any needed transformation or modification.


==== Simple scenario (Route certificate)

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
  namespace: test
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  expose: true
  route:
    host: myapp.mycompany.com
    termination: reencrypt
    certificate: {}
----
In this scenario the operator generates a `Certificate` resource with the common name of `myapp.mycompany.com` that will be injected into the `Route` resource.

==== Advanced scenario

In this example we are overriding Issuer to be used for application. Certificate will be generated for specific organization and duration. Extra properties can be added as well.

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
  namespace: test
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  expose: true
  route:
    host: myapp.mycompany.com
    termination: reencrypt
    certificate:
      duration: 8760h0m0s
      organization:
        - My Company
      issuerRef:
        name: myComanyIssuer
        kind: ClusterIssuer
----

==== Use existing certificates

It is possible to bring your own certificates to be used in a pod and the route.
In this case the cert-manager is not required.

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
  namespace: test
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  expose: true
  route:
    host: myapp.mycompany.com
    termination: reencrypt
    certificateSecretRef: my-app-rt-tls
  service:
    port: 9443
----

Example of the manually provided route secret

[source, yaml]
----
kind: Secret
apiVersion: v1
metadata:
  name: my-app-rt-tls
data:
  ca.crt: >-
    Certificate Authority public certificate...(base64)
  tls.crt: >-
    Route public certificate...(base64)
  tls.key: >-
    Route private key...(base64)
  destCA.crt: >-
    Pod/Service certificate Certificate Authority (base64). Might be required when using reencrypt termination policy.
type: kubernetes.io/tls
----

=== Affinity

Using affinity you can constrain a Pod to only be able to run on particular Node(s), or to prefer to run on particular nodes.

==== Node Affinity


===== Basic node affinity

Use `nodeAffinityLabels` field to set required labels for pod scheduling on specific nodes:

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
  namespace: test
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  affinity:
    nodeAffinityLabels:
      customNodeLabel: label1, label2
      customNodeLabel2: label3
----

===== Advanced node affinity example:

The following example requires a node type of _Large_ and preferences for two zones, which are named _zoneA_ and _zoneB_

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: my-app
  namespace: test
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key:  node.kubernetes.io/instance-type
            operator: In
            values:
            - large
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 60
        preference:
          matchExpressions:
          - key: failure-domain.beta.kubernetes.io/zone
            operator: In
            values:
            - zoneA
      - weight: 20
        preference:
          matchExpressions:
          - key: failure-domain.beta.kubernetes.io/zone
            operator: In
            values:
            - zoneB
----

==== Pod Affinity and Anti-Affinity

Pod affinity and anti-affinity allow you to constrain which nodes your pod is eligible to be scheduled based on labels on pods that are already running on the node rather than based on labels on node.

The following example shows that pod affinity is required and that the pods for _Service-A_ and _Service-B_ must be in the same zone. Through pod anti-affinity, it is preferred not to schedule _Service_B_ and _Service_C_ on the same host.

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeComponent
metadata:
  name: Service-B
  namespace: test
spec:
  applicationImage: quay.io/my-repo/my-app:1.0
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: service
            operator: In
            values:
            - Service-A
        topologyKey: failure-domain.beta.kubernetes.io/zone
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: service
              operator: In
              values:
              - Service-C
          topologyKey: kubernetes.io/hostname
----

See link:++https://github.com/application-stacks/runtime-component-operator/blob/master/examples/affinity/README.adocd++[Affinity Example] for more details

=== Day-2 Operations

You can easily perform day-2 operations using the `RuntimeOperation` custom resource (CR), which allows you to specify the commands to run on a container within a Pod.

.Configurable Parameters
|===
| Parameter       | Description
| `podName`       | The name of the Pod, which must be in the same namespace as the `RuntimeOperation` CR.
| `containerName` | The name of the container within the Pod. The default value is the name of the main container, which is `app`.
| `command`       | Command to run. The command doesn't run in a shell.
|===

Example:

[source,yaml]
----
apiVersion: app.stacks/v1beta1
kind: RuntimeOperation
metadata:
  name: example-runtime-operation
spec:
  # Specify the name of the pod. The pod must be in the same namespace as this RuntimeOperation CR.
  podName: Specify_Pod_Name_Here
  # Specify the name of the container. The default value is the name of the main container, which is `app`.
  containerName: app
  # Run the following command. The command does not run in a shell.
  command:
    - /bin/sh
    - '-c'
    - echo "Hello" > /tmp/runtime-operation.log
----

You can check the status of a runtime operation by using the `status` field inside the CR YAML file. You can also run the `oc get runtimeop -o wide` command to see the status of all operations in the current namespace.

The operator will retry to run the `RuntimeOperation` when it fails to start due to specified pod or container not being found or when the pod is not in running state. The retry interval will be doubled with each failed attempt. 

NOTE: The `RuntimeOperation` CR must be created in the same namespace as the Pod to operate on. After the `RuntimeOperation` CR starts, the CR cannot be reused for more operations. A new CR needs to be created for each day-2 operation. The operator can process only one `RuntimeOperation` instance at a time. Long running commands can cause other runtime operations to wait before they start.

=== Troubleshooting

See the link:++troubleshooting.adoc++[troubleshooting guide] for information on how to investigate and resolve deployment problems.
